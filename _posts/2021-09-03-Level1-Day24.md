---
layout: post
title:  "[Boostcamp AI Tech] 24일차 학습정리"
subtitle:   "Naver Boostcamp AI Tech Level1 Day24"
categories: "Boostcamp-AI-Tech"
tags: [5주차]
use_math: true
---

# 부스트캠프 24일차

## 📝 오늘 일정 정리

* 9/3 (금)
  - [x] 스페셜 피어세션 16:00~17:00
  - [x] 마스터클래스 9/3 (금) 18:00~19:00 대회 랩업 - 솔루션 발표, 피드백, 질의응답 (김태진 마스터님)
  - [x] Wrap UP 리포트 제출 (토요일 1자정까지)
    - [x] (팀) 리포트 (분량 제한: 2~3장) - 타인이 봤을때 어떤 대회를 진행했고, 어떤 모델링을 수행했는지 명확히 알 수 있도록 요약 정리
    - [x] (팀) 대회 최종 코드
    - [x] (개인) 대회 회고글 (분량 제한: 1~3장)

## 🍂 스페셜 피어세션

* 팀 협업 방법
  * 베이스라인에서 각자 성능 좋았던 것을 베이스라인으로 잡고 브랜치 따서 시도
  * 노션에 프로젝트 보드에 실험 내용 정리
  * 하이퍼파라미터까지 구체적으로 공유하는게 중요하다고 느낌
  * 서로 잘 하는 것들을 맡아서 업무 분담하는 것이 중요하다.
  * 줌으로 정말 자주 만났다. (바로바로 궁금증 해결!)
  * 재밌는 활동 - 5분 TED : 하루에 한명씩 돌아가면서 팀에 기여할 수 있는 지식 같은거 공유
* 좋았던 방법들
  * wandb : 실험 이름으로 필터링, 그룹화, 태그 등의 기능도 있다.
  * 테스트 데이터를 클래스별로 뽑아서 확인 : 빨간색 옷입으면 다 여자로 분류한다는 것을 발견, 옷을 자르자!(centercrop)
  * 나이를 나누는 기준을 hyperparameter로 튜닝 해봤는데, 29, 59로 나누는거나 60세 이상의 바운더리만 낮춰서 라벨링한 것이 효과가 좋았다.
  * TTA : augmentation을 다르게 적용한 데이터로더 3개 만들어서 적용하고 soft/hard voting 했다.
  * 모델에서 마지막 fc만 세개로 둬서 각각 예측하고 합쳤다. 아예 세 모델을 따로 만든 것보다는 좋았던 것 같다.

## 🌱 피어 세션 정리

* 이번 주 팀 회고
* P-Stage Wrap Up 리포트 작성

## 💎 마스터 클래스

### 토론왕 발표 

* 주제 : 같이 공부해요!
* 인간지능 : 당연히 하면 좋지만, 귀찮은 것

### 리더보드 솔루션 발표

#### 1등 팀 솔루션

* 기초 데이터 분석
  * 인간지능을 통해서 잘못된 데이터 찾는데에 많은 시간 투자
  * 50대와 60대가 구분이 어렵다는 것을 깨달음
  * 클래스 분포확인 : weighted ramdom sampler 사용
* Data Augmentation
  * rand augmentation : 수많은 augmentation 중에 랜덤하게 두개 선택해서 적용
  * cutout 등
  * face crop을 하진 않음
* 추가 데이터 사용 : 큰 효과를 보진 못함
  * Fair Face
  * meggage_asian 
* 모델
  * ResNet 계열 중에 resnet18 이 제일 잘 나왔다.
    * 데이터셋이 작은 편이기 때문에, 큰 모델은 오버피팅을 하지 않을까
  * 앙상블에 Efficientnet-b0 사용
* Loss : label smoothing 0.05, 사실 큰 성능 향상은 없음
* optimizer : Adam, lr : 0.00006
* Model Split by Class : 세개의 영역으로 나눠서 학습 시키고 이를 가지고 예측
* Pseudo Labeling : 바운더리 경계가 부드러워지는 효과가 있다.

#### 2등 팀 솔루션

* 데이터셋
  * age 모델에 좀 더 집중했다.
  * 데이터셋을 분할해서 저장했다. stratify 하게 분할
  * old 데이터가 많이 없어서 58세 이상을 old class 로 분류
* 추가 데이터 : 아시아인의 데이터 사용
* Data augmentation
  * facenet, retinanet 으로 얼굴 부분 자르기
  * cutout, gaussian noise, glass blur -> 사실상 적용은 안함
* 모델 : vgg16, vit...실험 -> 최종적으로 resnet 152 사용
* loss : label smoothing
* pseudo labeling : semi-supervised learning
* k-fold + soft voting 은 적용하지 못했다.

#### 모 캠퍼님의 p stage 를 겪고난 후기

* 당장의 퍼포먼스는 낮을지 몰라도, 성장 가속도는 내가 더 높을수도 있다!
* 나의 성장에 집중하자!

### 마스터 피드백 & 리뷰

* 1기보다 다양하고 다채로운 시도가 있었다.
* 마스크 분류 문제 + 성별과 나이 예측 : 마스크만 하면 정말 잘 나온다. 중간에 노이즈 섞은게 성별과 나이
* 데이터셋의 신뢰도를 아는 것이 중요하다! (추가 비용을 지불하더라도)
  * 데이터셋의 노이즈는 자연에서 자연스럽게 발생할 수 있는 것
  * 이 문제를 발견하는 것부터가 시작이다.
* 솔루션 공통적으로 모델을 세개로 나눴다.
* 인간지능 : 데이터를 확인할 수 있는 가장 확실한 방법
* 수도 레이블링
  * 불편한 단점이 있지만, 캐글에서도 많이 사용하는 방식
  * 사실 테스트 데이터를 사용했기 때문에, 100% 좋은 방법이라고 보기는 어렵다.
  * 허와 실을 잘 알고 사용하자

### 마스터 질의응답

* 포트폴리오 조언
  * 레주메는 간단하게
  * 각 프로젝트를 파이프라인, 결과 분석 등으로 정리해서 ppt 5장 정도로 만들고 링크 걸기
  * 가장 중요한건 문제 해결 능력
* 노트북/ide : 둘 다 자기만의 프로젝트 템플릿을 만드는 것이 중요할 것 같다.
* 공부 방법
  * 개발 실력? 시험에 나올 것만 공부하는 사람 vs 시험에 안나오더라도 궁금해서 공부하는 사람은 앞으로 차이가 있을 것이다.
  * 내가 이해했던걸 다시 뱉어서 검증해보는 시간을 가지자, 누군가가 했던 길만 따라가는게 아니라!

## 🚀 학습 회고

* 뭔가 생각보다 다른 팀들은 더 다양한 아이디어를 구상하고 실험해본 것 같다.
* 그리고 무엇보다 데이터 EDA를 통해서 그 데이터에 맞는 솔루션을 찾는게 중요하다는 것을 깨달았다.
* 이번 대회에서 연습해본 내용을 바탕으로 앞으로 있을 대회에서는 더 좋은 결과도 만들 수 있으면 좋을 것 같다.
