---
layout: post
title:  "[Boostcamp AI Tech] 21일차 학습정리"
subtitle:   "Naver Boostcamp AI Tech Level1 Day21"
categories: "Boostcamp-AI-Tech"
tags: [5주차, Level1-P-Stage]
use_math: true
---

# 부스트캠프 21일차

## 📝 오늘 일정 정리

* 8/31 (화)
  - [x] 대회 진행 내용
    - [x] train/valid split by profile and stratified labels
    - [x] confusion matrix 그려보기
    - [x] pre-trained model의 dropout 비율 바꿔보기

## 🌱 피어 세션 정리

- 한 모델로 학습/세 모델로 나눠서 학습하는 모듈 추가
- pretrained 모델에 dropout=0.7 (drop_rate in timm)
- train/valid split : 사람별로 나누되, 라벨별로 균등하게
- Densenet이 다른 모델보다 2% 정도 높게 나왔다.
- augmentation : 가우시안, Cutmix, sharpness, contrast 등을 이용해보자

## 🚩 대회 진행 내용

### train/valid split by profile and stratified labels

* 코드
  ```python
  from pandas_streaming.df import train_test_apart_stratify
  def split_dataset(self) -> Tuple[Subset, Subset]:
      df = pd.DataFrame({"indexs":self.indexs, "groups":self.groups, "labels":self.all_labels})
      train, valid = train_test_apart_stratify(df, group="groups", stratify="labels", test_size=self.val_ratio)
      train_index = train["indexs"].tolist()
      valid_index = valid["indexs"].tolist()
      return  [Subset(self, train_index), Subset(self, valid_index)]
  ```

### confusion matrix 그려보기

* 코드
  ```python
  model.eval()
  targets_list = list()
  preds_list = list()
  for i, (images, targets) in enumerate(train_loader) : 
      images = images.to(device)
      targets = targets.to(device)
  
      with torch.no_grad():
          scores = model(images)
          _, preds = scores.max(dim=1)
  
      targets_list.extend(targets.cpu())
      preds_list.extend(preds.cpu())
  
  cm = confusion_matrix(targets_list, preds_list)
  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(18))
  fig, ax = plt.subplots(figsize=(10, 10))
  disp.plot(ax=ax, cmap=plt.cm.Blues)
  ```

* 그래프

  |                       Confusion Matrix                       |                  Confusion Matrix (no diag)                  |
  | :----------------------------------------------------------: | :----------------------------------------------------------: |
  | ![image](https://user-images.githubusercontent.com/35680202/131479099-8d0e3f93-6a2b-4079-ba0d-cd5852b62937.png) | ![image](https://user-images.githubusercontent.com/35680202/131480362-6098385d-39d9-4b97-96ba-aef3784fae5d.png) |

* 분석
  * 나이
    * 마스크를 쓰면 나이인식이 어려워진다.
      * 0-1, 1-0, 1-2, 2-1 : wear - male - [0~30 or 30~60 or 60~]
      * 3-4, 4-5 : wear - female - [0~30 or 30~60 or 60~]
    * 마스크를 제대로 안 써도 나이 인식이 어려워진다.
      * 7-8, 8-7 : incorrect - male - [30~60 or 60~]
      * 10-9, 11-10 : incorrect - female - [0~30 or 30~60 or 60~]
  * 성별
    * 마스크를 쓰면 성별 인식도 어려워진다.
      * 0-3, 3-0, 1-4, 4-1 (남/여 모두 혼동) : wear - [male or female] - 0~60
      * 9-6, 10-7 (여를 남으로 인식) : incorrect - [male or female] - 0~60
    * 마스크를 안 쓰면 여자를 남자로 인식한다.
      * 15-12, 16-13, 17-14 : not wear - [male or female] - 0~100

### pre-trained model의 dropout 비율 바꿔보기

* 코드
  ```python
  class EfficientNet_b3_dropout(nn.Module):
      def __init__(self, num_classes):
          super().__init__()
          self.model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=num_classes, drop_rate=0.7)
  
      def forward(self, x):
          return self.model(x)
  ```

* 결과

  |                           적용 전                            |                           적용 후                            |
  | :----------------------------------------------------------: | :----------------------------------------------------------: |
  | ![image](https://user-images.githubusercontent.com/35680202/131479099-8d0e3f93-6a2b-4079-ba0d-cd5852b62937.png) | ![image](https://user-images.githubusercontent.com/35680202/131493768-5fdeb363-e69c-4e1f-b3a3-afe28af2af6f.png) |
  | ![image](https://user-images.githubusercontent.com/35680202/131480362-6098385d-39d9-4b97-96ba-aef3784fae5d.png) | ![image](https://user-images.githubusercontent.com/35680202/131493854-94a6811d-65f9-4f77-ba72-c90d5599ede0.png) |
  |   [val] best acc: 88.21%, best loss: 0.4, best f1: 0.8139    |   [val] best acc: 89.11%, best loss: 0.33, best f1: 0.8137   |

  * 수치적으로는 성능이 비슷하지만, 일부 클래스 예측 오차가 늘었다.


## 🚀 학습 회고

* 어제는 팀 코드에 합치는 작업이 필요없어 보였는데, 각자의 기능을 합쳐서 사용하려고 할 때 도움이 되어서 하길 잘 했다는 생각이 들었다.
* 성능을 높이는게 쉽지 않지만, 나름대로 결과를 분석해보는 것도 재밌는 것 같다.

