---
layout: post
title:  "[Boostcamp AI Tech] 18일차 학습정리"
subtitle:   "Naver Boostcamp AI Tech Level1 Day18"
categories: "Boostcamp-AI-Tech"
tags: [4주차, Level1-P-Stage]
use_math: true
---

# 부스트캠프 18일차

## 📝 오늘 일정 정리

* 8/26 (목)
  - [x] 이미지 분류 강의
    - [x] (7강) Training & Inference 1
    - [x] (8강) Training & Inference 2
  - [x] 스페셜 미션 : Training & Inference
  - [x] 마스터클래스 8/26 (목) 18:00~19:00 AMA - 대회 설계 의도, 현업 소개와 취업 조언 (김태진 마스터님)
  - [x] 멘토링 20:00~

## 📚 강의 내용 정리

### [7강] Training & Inference 1 - Loss, Optimizer, Metric

* Loss : Loss 함수 = Cost 함수 = Error 함수
  * `nn.Module` 을 상속하고 있다. (forward 함수 포함)
  * `loss.backward()` : `required_grad=True`인 모델의 파라미터의 grad 값이 업데이트 된다.
  * Focal loss : Class Imbalance 문제가 있는 경우, 맞출 확률이 높은 Class는 조금의 loss를, 맞춘 확률이 낮은 Class는 Loss를 훨씬 높게 부여
  * Label Smoothing Loss : Class target label을 Onehot 표현으로 사용하기 보다는 Soft하게 표현에서 일반화 성능을 높이기 위함
* Optimizer : 어느 방향으로, 얼마나 움직일지 결정
  * $w' = w - \eta \frac{\partial E}{\partial w}$
    * $\eta$ : 학습률(Learning rate)
    * $\frac{\partial E}{\partial w}$ : 방향
  * LR scheduler : 학습 시에 Learning rate를 동적으로 조절
    * StepLR : 특정 Step마다 LR 감소
    * CosineAnnealingLR : Cosine 함수 형태처럼 LR을 급격히 변경
    * ReduceLROnPlateau : 더 이상 성능 향상이 없을 때 LR 감소
* Metric : 학습된 모델을 객관적으로 평가할 수 있는 지표
  * Classification : Accuracy, F1-score, precision, recall, ROC&AUC
    * Accuracy : Class 별로 밸런스가 적절히 분포하는 경우
    * F1-Score : Class 별 밸런스가 좋지 않아서 각 클래스 별로 성능을 잘 낼 수 있는지 확인 필요
      * [macro vs micro vs weighted vs samples](https://stackoverflow.com/questions/55740220/macro-vs-micro-vs-weighted-vs-samples-f1-score)
  * Regression : MAE, MSE
  * Ranking : MRR, NDCG, MAP

### [8강] Training & Inference 2 - Process

* Training Process
  * `model.train()` : 모델을 train 모드로 만들기 (`Dropout`이나 `BatchNorm` 등은 학습/추론 시 동작이 다르기 때문)
  * `optimizer.zero_grad()` : 각각의 파라미터의 grad를 0으로 만드는 작업
  * `loss = criterion(output, labels)` : criterion이 nn.Module을 상속하고 있기 때문에 forward 함수를 가지고 있고, input 부터 시작해서 계산 그래프가 완성된다.
  * `loss.backward()` : 계산 그래프가 완성된 후 backward를 진행할 수 있다.
  * `optimizer.step()` : 파라미터 업데이트
  * Gradient Accumulation : 여러 개의 배치에서의 loss를 하나의 배치에서 step하듯이 학습하고 싶을 때 응용할 수 있다.
* Inference Process
  * `model.eval()` : 모델을 eval 모드로 만들기
  * `with torch.no_grad()` : inference 시의 계산은 gradient나 파라미터의 변화 없이 진행되어야 한다.
  * 검증(Validation) 확인 후 좋은 결과를 Checkpoint로 저장
  * 최종 Output, Submission 형태로 변환
* Appendix : Pytorch Lightning
  * Keras와 비슷하다. 생산성 측면에서 좋다.
  * 그래도 공부는 Pytorch로 하는 것이 좋다.

## 🚩 대회 진행 내용

* 실험 관리를 잘 하기 위해 pytorch-template 을 이용하려고 했는데, 구조 파악이 아직까지는 어려웠다.

## 🌱 피어 세션 정리

* 이번 주 까지 각자 목표한 바 대로 진행하기
* 외부 데이터 사용 가능하니까 시도해보기
* confusion matrix를 그려보고 어떤 부분을 보완할지 생각해보기

## 💎 마스터 클래스

* Stage 도중 Stage 설명하는 Stage
  * 최상위 목표 : Data로 Value를 만들어내는 일
  * U stage 복습 및 확장의 발판
  * 리눅스, 데이터, 이미지의 형태, 파이토치 학습, 라이브러리 학습, Augmentation 등 경험하면서 다음 스테이지 준비하기
  * Competition에서 점수가 좋은 것보다는 어떤 가정/가설을 세웠고, 어떤 걸 활용했고, 어떤 결과를 냈는지가 더 중요하다. 즉, 많은 시행착오와 경험, 문제해결의 기댓값이 높은 사람을 원한다.
  * Competition = Compete + Share
  * 실력을 빠르게 올릴 수 있는 비결 = 내 실력을 먼저 인정하는 것
  * Input에서 Output을 만들 수 있는 프로세스를 만들 수 있도록 구조를 빠삭하게 이해하기

## 🌼 멘토링

* TIP
  * [tmux를 예쁘게 쓰는 법](https://github.com/gpakosz/.tmux)
  * [PEP 8 -- Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008/)
  * tqdm : 학습 진행 상황 로딩 바로 보기
* 프로젝트 파이썬 코드 리뷰
  * 모델 저장할 때 config 파일도 같이 저장하기
  * import \* 보다는 뭘 import 하는지 정확히 써주는 것이 좋다.
  * 코드에 주석을 적당히 써주는 것이 좋다.
  * 전역 변수로 만들기보다는 함수로 떼어내서 만드는 것이 좋다.
  * 메인에서 실행하는 코드는 `If __name__ == “__main__”:` 안에 넣어주기 : import 될 때는 실행 안되고, python 명령으로 그 파일을 실행할 때만 코드가 실행된다.
* Class Imbalance 문제 해결 팁
  * Oversampling / Undersampling
  * 각 클래스를 Binary classification 해서 학습하고 앙상블하기
  * 각 클래스를 인식 못하는게 score에 얼마나 미치는지 알아보기
  * loss에 weight 곱하기 : weight도 하이퍼파라미터, 데이터 분포 알아보고, 적절하게 곱하기
* valid 성능과 리더보드 성능이 너무 다를 때
  * cross validation으로 쪼개서 학습한 후에 가장 유사하게 나오는 validation set을 찾는 것도 방법이다.
  * **train/valid 나눌 때 같은 사람은 같은 데이터셋에 넣자! 그래야 valid의 의미가 있다.**

## 🔎 스페셜 미션

* Evaluation 과정에서 Checkpoint 모델 저장하기
* F1-score Metric 등을 매 에폭마다 확인하기
* 학습 과정에서 진전이 없으면 학습 멈추기 : [Ignite](https://pytorch.org/ignite/) / [Catalyst](https://catalyst-team.github.io/catalyst/index.html)
* Gradient Accumulation 적용해보기
* [Optimizer와 Scheduler의 종류와 방식, 옵션](https://www.kaggle.com/isbhargav/guide-to-pytorch-learning-rate-scheduling) 등을 알아보고 적용해보기
* [Label smoothing](https://3months.tistory.com/465), Focal loss, [F1 Loss](https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354) 등 새로운 Loss를 만들어 학습에 사용해보기

## 🚀 학습 회고

* train/valid set을 나눌 때, 클래스가 일정하게 나뉘는 것만 신경썼는데, 아무래도 같은 사람의 사진이 여러 장 있다보니까, 사람을 기준으로 나누는게 의미가 있을 것이라는 것을 처음 깨닫게 되었다.

