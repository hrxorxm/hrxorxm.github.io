---
layout: post
title:  "[Boostcamp AI Tech] 19일차 학습정리"
subtitle:   "Naver Boostcamp AI Tech Level1 Day19"
categories: "Boostcamp-AI-Tech"
tags: [4주차]
use_math: true
---

# 부스트캠프 19일차

## 📝 오늘 일정 정리

* 8/27 (금)
  - [x] 이미지 분류 강의
    - [x] (9강) Ensemble
    - [x] (10강) Experiment Toolkits & Tips
  - [x] 스페셜 미션 : Ensemble / Experiment Toolkits
  - [x] 오피스아워 8/27 (금) 18:00~19:00 베이스라인 코드 설명 (김보찬 멘토님)

## 📚 강의 내용 정리

### [9강] Ensemble

* Ensemble(앙상블) : 서로 다른 여러 학습 모델을 사용하여 하나의 모델보다 더 나은 성능을 만들고자 하는 것
  * Model Averaging(Voting) : 다른 모델이 같은 에러를 만들어내지 않을 것이기 때문에 잘 동작한다.
    * Hard Voting : 각각 예측 후 다수결
    * Soft Voting : 점수를 모아서 예측
  * Cross Validation : 훈련 셋과 검증 셋을 분리하되, 검증 셋을 학습에 활용하고 싶다.
    * 모델을 평가하는 지표로서 사용될 수 있다.
    * Stratified K-fold Cross Validation : split 시에 class 분포까지 고려
  * TTA(Test Time Augmentation) : 테스트 이미지를 Augmentation 후 모델 추론, 출력된 여러가지 결과를 앙상블
  * 앙상블 효과는 확실히 있지만, 성능과 효율의 Trade-off 가 있다.
* Hyperparameter Optimization
  * Hyperparameter : 시스템 매커니즘에 영향을 주는 주요한 파라미터
    * Hidden Layer 갯수, k-fold
    * Learning rate, Batch size
    * Loss 파라미터, Optimizer 파라미터
    * Dropout, Regularization
  * 시간과 장비가 충분하다면 시도해볼 수 있긴 하다.
  * Optuna : 파라미터 범위를 주고 그 범위 안에서 trials 만큼 시행한다.

### [10강] Experiment Toolkits & Tips

* Training Visualization
  * Tensorboard : 학습 과정을 기록하고, 트래킹할 수 있다.
    * `tensorboard --logdir PATH --host ADDR --port PORT`
    * ADDR : 원격 서버에서 사용시 `0.0.0.0`로 지정 (default: localhost)
    * PORT : AI Stages 서버에서 열어준 포트번호는 `6006`
  * Weight and Bias (wandb) : 딥러닝 로그의 깃허브 같은 느낌
    * wandb login 처음 1회만 하면 사용 가능
    * 파이썬 코드에서 wandb init, log 설정하여 사용하기
* Machine Learning Project
  * Jupyter Notebook
    * 장점
      * 코드를 아주 빠르게 cell 단위로 실행해볼 수 있다.
      * EDA 등 데이터 분석을 할 때 데이터를 로드해놓고 여러가지 작업할 수 있다.
    * 단점
      * 학습 도중 노트북 창이 꺼지면 tracking이 잘 안됨
  * Python IDLE
    * 장점
      * 구현은 한번만, 사용은 언제든, 간편한 코드 재사용
      * 디버깅 툴이 강력하다.
      * 자유로운 실험 핸들링
* Some Tips
  * 다른 사람의 분석을 볼 때는 코드 보다는 설명글(필자의 생각 흐름)을 유심히 보자
  * 코드를 볼 때는 디테일한 부분까지 보자
  * [Paper with Codes](https://paperswithcode.com/) : 최신 논문과 그 코드까지 확인할 수 있다.
  * 공유하는 것을 주저하지 말자. 새로운 배움의 기회가 될 수 있다.

## 🚩 대회 진행 내용

* k-fold, stratified k-fold 등의 앙상블 기법을 적용해보았다.
* train/valid를 사람 기준으로 나누니까 역시 valid 성능이 리더보드와 비슷해졌다. 앞으로 이런 점들을 주의해야 할 것 같다.

## 🌱 피어 세션 정리

* class weight보다 label smoothing을 해보자
* [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)로 결과 확인해보자
* 앙상블 기법 사용해보자 - [torch ensemble 라이브러리](https://ensemble-pytorch.readthedocs.io/en/latest/quick_start.html)
* face crop 기법 사용해보자 - [facenet_pytorch 라이브러리](https://github.com/timesler/facenet-pytorch)
* grad cam 으로 모델을 이해해보자 - [grad cam 라이브러리](https://github.com/jacobgil/pytorch-grad-cam)

## 💎 오피스 아워

* baseline code 
  * 목적
    * 말 그대로 템플릿, 큰 뼈대
    * 새로운 아이디어를 추가하기 좋기
    * 실험관리를 잘 하도록
  * Python Project
    * 파일들을 구조화하여 관리하기 편함, 확장성, 재사용성, 가독성
    * CLI 사용에 용이
    * 다양한 실험 세팅과 결과 versioning에 용이
  * Tools
    * tensor board : `tensorboard --logdir=run --host=0.0.0.0 --port=6006`
    * pycharm : education / professional 으로 서버 동기화 기능 사용 가능
    * 똑같은거 두번 찾아보지 말고 템플릿으로 만들어 놓자 (코딩할 때 텐션 떨어뜨리지 말자)
  * 조언
    * 베이스라인에서 필요한 부분만 가져가도 되고, 베이스라인을 기반으로 바꿔가면서 실험의 감과 코드를 익히면 좋다.
    * 안 익숙한 것에 대해서 바꿔보면서 익히자. 그러면 어느 순간 혼자서 베이스라인을 작성할 수 있을 것이다.
* Auto ML Tasks
  * Hyperparameter Optimization(HPO)
    * [NNI(Neural Network Intelligence)](https://github.com/microsoft/nni) 사용해보기
    * W&B Sweeps : 팀으로 작업할 때 좋다.
    * Ray-Tune
    * Optuna
  * Neural Architecture Search(NAS)
  * Model Compression
* 개발자가 하는 일 : 코드를 짜는 것이 아니라, 커뮤니케이션과 문제해결이 핵심이다.

## 🔎 스페셜 미션

* [Strarified K-fold](https://stackoverflow.com/questions/60883696/k-fold-cross-validation-using-dataloaders-in-pytorch) : sklearn의 k-fold는 index로 데이터를 split 하므로, pytorch의 torch.utils.data.dataset.Subset()를 이용하여 train, valid set으로 분리해 DataLoader를 작성합니다.
* [Test Time Augmentation](https://www.kaggle.com/luyujia/pytorch-my-tta-function-easy-to-understand) : 직관적으로 이해하기 쉽게 Pytorch로 작성한 캐글 커널입니다. 해당 코드에서 transform 부분에 Augmentation 기법을 추가해주어 작성할 수 있습니다.
* Tensorboard, wandb 이용해서 학습 과정 모니터링
  * [PYTORCH로 TENSORBOARD 사용하기](https://tutorials.pytorch.kr/recipes/recipes/tensorboard_with_pytorch.html) / [TENSORBOARD로 모델, 데이터, 학습 시각화하기](https://tutorials.pytorch.kr/intermediate/tensorboard_tutorial.html)
  * [wandb 사용법](https://docs.wandb.ai/guides/integrations/pytorch) / [Weight & Biases(wandb) 사용법(wandb 설치 및 설명)](https://greeksharifa.github.io/references/2020/06/10/wandb-usage/)
* [Model Validation, Ensemble(OOF, Stacking)](https://www.kaggle.com/kcs93023/kakr-4th-seminar-model-validation-ensemble) : 캐글 코리아 4차 경진대회에서 공개된 Model, Validation, Ensemble 커널 ([유튜브 영상](https://youtu.be/G6i4folb2jo))

## 🚀 학습 회고

* 기존에 하던대로만 하지 말고, 새로운 유용한 라이브러리나 툴들을 적극적으로 사용하면 좋을 것 같다.
* 다음 주 계획
  * 노트북에서 파이썬 템플릿으로 옮기기
  * 중간 결과를 시각화해서 어떤 부분을 잘 학습하고 어떤 부분을 잘못 학습하고 있는지 파악하기
  * 위 결과를 바탕으로 가설을 세우고, 다양한 모델과 전처리 기법으로 실험해보며 검증하기
  * 좋았던 모델들을 앙상블하고, 하이퍼 파라미터 튜닝하기

