---
layout: post
title:  "[Boostcamp AI Tech] 22일차 학습정리"
subtitle:   "Naver Boostcamp AI Tech Level1 Day22"
categories: "Boostcamp-AI-Tech"
tags: [5주차]
use_math: true
---

# 부스트캠프 22일차

## 📝 오늘 일정 정리

* 9/1 (수)
  - [x] 대회 진행 내용
    - [x] optimizer, scheduler 바꿔보기
    - [x] grad cam 으로 모델 확인해보기
    - [x] augmentation : CutMix, Auto Augmentation
    - [x] face crop 다시 적용해보기
    - [x] 팀 코드에 합치고 돌려보기

## 🌱 피어 세션 정리

* Me : CutMix 적용 후 내 모델 중에서는 제일 좋은 성능을 보임
  * inference 할 때 testset augmentation 지정하는 코드 추가하기
  * train 에서 f1 score로 early stopping 하는 코드로 수정하기
  * cutmix 실험 후에 team 코드에 추가하기
* Team :
  * 평균적인 Facecrop과 Cutout 적용하여 학습 중
  * MaskSplitByClassDataset에 one by one 학습 적용 가능하게 수정
  * Confusion matrix one by one 학습에 사용 가능하게 수정
  * RetinaFace를 이용하여 FaceDetection을 통해서 face cropping을 진행
  * face cropping을 다시해서 마스크 위로만 추가로 cropping 시도중

## 🌼 멘토링

* ViT 써보기
* TTA : 단일 모델로 앙상블 효과를 내는 것
* [Auto Augmentation](https://github.com/4uiiurz1/pytorch-auto-augment)
* 좋은 방법론에서 전체 데이터셋을 이용해서 학습하기
* 제출 하기 전에 valid 성능을 보고 낼지 말지 정하기

## 🚩 대회 진행 내용

### optimizer, schedular 바꿔보기

* `optimizer = optim.RAdam(model.parameters(), lr=args.lr, betas=(0.9, 0.999), weight_decay=1e-4)`
* `scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs)`

### grad cam 으로 모델 확인해보기

* 라이브러리 : [pytorch-grad-cam](https://github.com/jacobgil/pytorch-grad-cam)
* 코드
  ```python
  columns = 5
  rows = 5
  fig = plt.figure(figsize=(12,12))
  
  mean = (0.548, 0.504, 0.479)
  std = (0.237, 0.247, 0.246)
  
  target_layer = model.model.blocks[-1][-1] # 모델이 바뀌면 수정해주기
  cam = GradCAM(model=model, target_layer=target_layer, use_cuda=True)
  target_category = 0 # 확인해보고 싶은 class
  
  model.eval()
  for i in range(1, columns*rows+1):
      fig.add_subplot(rows, columns, i)
      
      while True:
          data_idx = np.random.randint(len(train_loader.dataset))
          input_img = train_loader.dataset[data_idx][0].unsqueeze(dim=0).to(device)
          label = train_loader.dataset[data_idx][1]
  
          score = model(input_img.clone())
          _, pred = score.max(dim=1)
          pred_label = pred.cpu().numpy()[0]
  
          if pred_label == target_category:
              break
      
      if pred_label == label:
          plt.title(str(label)+"-"+str(pred_label)+' (O)')
      else:
          plt.title(str(label)+"-"+str(pred_label)+' (X)')
      
      plot_img = train_loader.dataset[data_idx][0]
      plot_img[0, :, :] = plot_img[2, :, :] * std[2] + mean[2]
      plot_img[1, :, :] = plot_img[1, :, :] * std[1] + mean[1]
      plot_img[2, :, :] = plot_img[0, :, :] * std[0] + mean[0]
      plot_img = transforms.functional.to_pil_image(plot_img)
      
      grayscale_cam = cam(input_tensor=input_img.clone().detach(), target_category=target_category
      grayscale_cam = grayscale_cam[0, :]
      visualization = show_cam_on_image(np.float32(plot_img) / 255, grayscale_cam, use_rgb=True)
      
      plt.imshow(visualization)
      plt.axis('off')
  ```
* 결과 : 대부분 얼굴 부분에 활성화되어있다는 것을 확인하였다.

### augmentation 다양하게 적용하기

#### CutMix

* 코드
  * transform : 얼굴이 중앙 쪽에 있으니 CenterCrop을 한 후에 resize
    ```python
    transform = transforms.Compose([
        CenterCrop((350, 300)),
        Resize(resize, Image.BILINEAR),
        ToTensor(),
        Normalize(mean=mean, std=std),
    ])
    ```
  * [`rand_bbox`](https://github.com/clovaai/CutMix-PyTorch/blob/2d8eb68faff7fe4962776ad51d175c3b01a25734/train.py#L279)
    ```python
    def rand_bbox(size, lam):
        W = size[2] 
        H = size[3] 
        cut_rat = np.sqrt(1. - lam)
        cut_w = np.int(W * cut_rat)
        cut_h = np.int(H * cut_rat)
    
        # uniform
        cx = np.random.randint(W)
        cy = np.random.randint(H)
      
        # 세로축으로만 자르기
        bbx1 = 0
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbx2 = W
        bby2 = np.clip(cy + cut_h // 2, 0, H)
      
        return bbx1, bby1, bbx2, bby2
    ```
  * [train](https://github.com/clovaai/CutMix-PyTorch/blob/master/train.py#L228)
    ```python
    if args.BETA > 0 and np.random.random() > 0.5: # cutmix가 실행될 경우     
        lam = np.random.beta(args.BETA, args.BETA)
        rand_index = torch.randperm(inputs.size()[0]).to(device)
        target_a = labels
        target_b = labels[rand_index]
        bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)
        inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]
        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))
        outs = model(inputs)
        loss = criterion(outs, target_a) * lam + criterion(outs, target_b) * (1. - lam)
    else:
        outs = model(inputs)
        loss = criterion(outs, labels)
    
    preds = torch.argmax(outs, dim=-1)
    ```

* 결과 : 성능이 좋아졌다. (acc 1%, f1-score 0.01 정도 상승)

#### Auto Augmentation

* 코드
  * [auto_augment.py](https://github.com/4uiiurz1/pytorch-auto-augment/blob/master/auto_augment.py)
  * [train.py](https://github.com/4uiiurz1/pytorch-auto-augment/blob/master/train.py)
  ```python
  from auto_augment import AutoAugment
  class AutoAugmentation:
      def __init__(self, resize, mean, std, **args):
          self.transform = transforms.Compose([
              CenterCrop((350, 300)),
              Resize(resize, Image.BILINEAR),
              AutoAugment(),
              ToTensor(),
              Normalize(mean=mean, std=std),
          ])
      def __call__(self, image):
          return self.transform(image)
  ```
* 결과
  ![image](https://user-images.githubusercontent.com/35680202/131697331-e3fa583b-4c74-4b67-b6f4-e00cb425ba0e.png)
  * CutMix와 비교해서 그래프가 대체로 낮고, 좋게 학습되지 못한 채 early stopping 된다.

### face crop 다시 적용해보기

* [Facenet Pytorch](https://github.com/timesler/facenet-pytorch)
* [Retinaface Pytorch](https://github.com/biubug6/Pytorch_Retinaface)
* Dataset 의 `__getitem__` 함수에 추가
  ```python
  # ===== Face Crop =====
  X_PADDING = 20
  Y_PADDING = 30
  # mtcnn 적용
  mtcnn = MTCNN(keep_all=True)
  boxes, probs = mtcnn.detect(image)
  if len(probs) > 1:
      xmin = int(boxes[0, 0]) - X_PADDING
      ymin = int(boxes[0, 1]) - Y_PADDING
      xmax = int(boxes[0, 2]) + X_PADDING
      ymax = int(boxes[0, 3]) + Y_PADDING
  else:
      # retinaface 적용
      image_path = self.image_paths[index]
      result_detected = RetinaFace.detect_faces(image_path)
      if type(result_detected) == dict:
          xmin = int(result_detected["face_1"]["facial_area"][0]) - X_PADDING
          ymin = int(result_detected["face_1"]["facial_area"][1]) - Y_PADDING
          xmax = int(result_detected["face_1"]["facial_area"][2]) + X_PADDING
          ymax = int(result_detected["face_1"]["facial_area"][3]) + Y_PADDING
      else:
          # 직접 crop
          xmin = 80
          ymin = 50
          xmax = 80 + 220
          ymax = 50 + 320
  if xmin < 0: xmin = 0
  if ymin < 0: ymin = 0
  if xmax > 384: xmax = 384
  if ymax > 512: ymax = 512
  image = image.crop([xmin, ymin, xmax, ymax])
  # transform
  image_transform = self.transform(image)
  ```

### 팀 코드에 합치고 돌려보기

- [x] CutMix 옮기기
- [x] Test Augmentation 추가하기
- [x] early stopping 조건 바꾸기
- [x] 전체 데이터셋 학습 추가하기

## 🚀 학습 회고

* 전체 데이터셋으로 학습하니까 확실히 성능이 좋아졌다. train/valid 로 나눠서 학습한 다음에는 그 학습 구조를 가지고 전체 데이터셋으로 학습시켜서 최종 모델로 사용해야겠다.
* 팀 코드로 합치는 작업이 처음에는 번거롭다고 생각했는데, 생각보다 너무 유용하고, 효율적이었다. 앞으로 진행되는 대회에서도 이러한 팀 협업을 잘 진행할 수 있을 것 같은 자신감이 생겼다.

