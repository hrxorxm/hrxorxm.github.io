---
layout: post
title:  "[Boostcamp AI Tech] 22ì¼ì°¨ í•™ìŠµì •ë¦¬"
subtitle:   "Naver Boostcamp AI Tech Level1 Day22"
categories: "Boostcamp-AI-Tech"
tags: [5ì£¼ì°¨]
use_math: true
---

# ë¶€ìŠ¤íŠ¸ìº í”„ 22ì¼ì°¨

## ğŸ“ ì˜¤ëŠ˜ ì¼ì • ì •ë¦¬

* 9/1 (ìˆ˜)
  - [x] ëŒ€íšŒ ì§„í–‰ ë‚´ìš©
    - [x] optimizer, scheduler ë°”ê¿”ë³´ê¸°
    - [x] grad cam ìœ¼ë¡œ ëª¨ë¸ í™•ì¸í•´ë³´ê¸°
    - [x] augmentation : CutMix, Auto Augmentation
    - [x] face crop ë‹¤ì‹œ ì ìš©í•´ë³´ê¸°
    - [x] íŒ€ ì½”ë“œì— í•©ì¹˜ê³  ëŒë ¤ë³´ê¸°

## ğŸŒ± í”¼ì–´ ì„¸ì…˜ ì •ë¦¬

* Me : CutMix ì ìš© í›„ ë‚´ ëª¨ë¸ ì¤‘ì—ì„œëŠ” ì œì¼ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„
  * inference í•  ë•Œ testset augmentation ì§€ì •í•˜ëŠ” ì½”ë“œ ì¶”ê°€í•˜ê¸°
  * train ì—ì„œ f1 scoreë¡œ early stopping í•˜ëŠ” ì½”ë“œë¡œ ìˆ˜ì •í•˜ê¸°
  * cutmix ì‹¤í—˜ í›„ì— team ì½”ë“œì— ì¶”ê°€í•˜ê¸°
* Team :
  * í‰ê· ì ì¸ Facecropê³¼ Cutout ì ìš©í•˜ì—¬ í•™ìŠµ ì¤‘
  * MaskSplitByClassDatasetì— one by one í•™ìŠµ ì ìš© ê°€ëŠ¥í•˜ê²Œ ìˆ˜ì •
  * Confusion matrix one by one í•™ìŠµì— ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ìˆ˜ì •
  * RetinaFaceë¥¼ ì´ìš©í•˜ì—¬ FaceDetectionì„ í†µí•´ì„œ face croppingì„ ì§„í–‰
  * face croppingì„ ë‹¤ì‹œí•´ì„œ ë§ˆìŠ¤í¬ ìœ„ë¡œë§Œ ì¶”ê°€ë¡œ cropping ì‹œë„ì¤‘

## ğŸŒ¼ ë©˜í† ë§

* ViT ì¨ë³´ê¸°
* TTA : ë‹¨ì¼ ëª¨ë¸ë¡œ ì•™ìƒë¸” íš¨ê³¼ë¥¼ ë‚´ëŠ” ê²ƒ
* [Auto Augmentation](https://github.com/4uiiurz1/pytorch-auto-augment)
* ì¢‹ì€ ë°©ë²•ë¡ ì—ì„œ ì „ì²´ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ì„œ í•™ìŠµí•˜ê¸°
* ì œì¶œ í•˜ê¸° ì „ì— valid ì„±ëŠ¥ì„ ë³´ê³  ë‚¼ì§€ ë§ì§€ ì •í•˜ê¸°

## ğŸš© ëŒ€íšŒ ì§„í–‰ ë‚´ìš©

### optimizer, schedular ë°”ê¿”ë³´ê¸°

* `optimizer = optim.RAdam(model.parameters(), lr=args.lr, betas=(0.9, 0.999), weight_decay=1e-4)`
* `scheduler = CosineAnnealingLR(optimizer, T_max=args.epochs)`

### grad cam ìœ¼ë¡œ ëª¨ë¸ í™•ì¸í•´ë³´ê¸°

* ë¼ì´ë¸ŒëŸ¬ë¦¬ : [pytorch-grad-cam](https://github.com/jacobgil/pytorch-grad-cam)
* ì½”ë“œ
  ```python
  columns = 5
  rows = 5
  fig = plt.figure(figsize=(12,12))
  
  mean = (0.548, 0.504, 0.479)
  std = (0.237, 0.247, 0.246)
  
  target_layer = model.model.blocks[-1][-1] # ëª¨ë¸ì´ ë°”ë€Œë©´ ìˆ˜ì •í•´ì£¼ê¸°
  cam = GradCAM(model=model, target_layer=target_layer, use_cuda=True)
  target_category = 0 # í™•ì¸í•´ë³´ê³  ì‹¶ì€ class
  
  model.eval()
  for i in range(1, columns*rows+1):
      fig.add_subplot(rows, columns, i)
      
      while True:
          data_idx = np.random.randint(len(train_loader.dataset))
          input_img = train_loader.dataset[data_idx][0].unsqueeze(dim=0).to(device)
          label = train_loader.dataset[data_idx][1]
  
          score = model(input_img.clone())
          _, pred = score.max(dim=1)
          pred_label = pred.cpu().numpy()[0]
  
          if pred_label == target_category:
              break
      
      if pred_label == label:
          plt.title(str(label)+"-"+str(pred_label)+' (O)')
      else:
          plt.title(str(label)+"-"+str(pred_label)+' (X)')
      
      plot_img = train_loader.dataset[data_idx][0]
      plot_img[0, :, :] = plot_img[2, :, :] * std[2] + mean[2]
      plot_img[1, :, :] = plot_img[1, :, :] * std[1] + mean[1]
      plot_img[2, :, :] = plot_img[0, :, :] * std[0] + mean[0]
      plot_img = transforms.functional.to_pil_image(plot_img)
      
      grayscale_cam = cam(input_tensor=input_img.clone().detach(), target_category=target_category
      grayscale_cam = grayscale_cam[0, :]
      visualization = show_cam_on_image(np.float32(plot_img) / 255, grayscale_cam, use_rgb=True)
      
      plt.imshow(visualization)
      plt.axis('off')
  ```
* ê²°ê³¼ : ëŒ€ë¶€ë¶„ ì–¼êµ´ ë¶€ë¶„ì— í™œì„±í™”ë˜ì–´ìˆë‹¤ëŠ” ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤.

### augmentation ë‹¤ì–‘í•˜ê²Œ ì ìš©í•˜ê¸°

#### CutMix

* ì½”ë“œ
  * transform : ì–¼êµ´ì´ ì¤‘ì•™ ìª½ì— ìˆìœ¼ë‹ˆ CenterCropì„ í•œ í›„ì— resize
    ```python
    transform = transforms.Compose([
        CenterCrop((350, 300)),
        Resize(resize, Image.BILINEAR),
        ToTensor(),
        Normalize(mean=mean, std=std),
    ])
    ```
  * [`rand_bbox`](https://github.com/clovaai/CutMix-PyTorch/blob/2d8eb68faff7fe4962776ad51d175c3b01a25734/train.py#L279)
    ```python
    def rand_bbox(size, lam):
        W = size[2] 
        H = size[3] 
        cut_rat = np.sqrt(1. - lam)
        cut_w = np.int(W * cut_rat)
        cut_h = np.int(H * cut_rat)
    
        # uniform
        cx = np.random.randint(W)
        cy = np.random.randint(H)
      
        # ì„¸ë¡œì¶•ìœ¼ë¡œë§Œ ìë¥´ê¸°
        bbx1 = 0
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbx2 = W
        bby2 = np.clip(cy + cut_h // 2, 0, H)
      
        return bbx1, bby1, bbx2, bby2
    ```
  * [train](https://github.com/clovaai/CutMix-PyTorch/blob/master/train.py#L228)
    ```python
    if args.BETA > 0 and np.random.random() > 0.5: # cutmixê°€ ì‹¤í–‰ë  ê²½ìš°     
        lam = np.random.beta(args.BETA, args.BETA)
        rand_index = torch.randperm(inputs.size()[0]).to(device)
        target_a = labels
        target_b = labels[rand_index]
        bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)
        inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]
        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))
        outs = model(inputs)
        loss = criterion(outs, target_a) * lam + criterion(outs, target_b) * (1. - lam)
    else:
        outs = model(inputs)
        loss = criterion(outs, labels)
    
    preds = torch.argmax(outs, dim=-1)
    ```

* ê²°ê³¼ : ì„±ëŠ¥ì´ ì¢‹ì•„ì¡Œë‹¤. (acc 1%, f1-score 0.01 ì •ë„ ìƒìŠ¹)

#### Auto Augmentation

* ì½”ë“œ
  * [auto_augment.py](https://github.com/4uiiurz1/pytorch-auto-augment/blob/master/auto_augment.py)
  * [train.py](https://github.com/4uiiurz1/pytorch-auto-augment/blob/master/train.py)
  ```python
  from auto_augment import AutoAugment
  class AutoAugmentation:
      def __init__(self, resize, mean, std, **args):
          self.transform = transforms.Compose([
              CenterCrop((350, 300)),
              Resize(resize, Image.BILINEAR),
              AutoAugment(),
              ToTensor(),
              Normalize(mean=mean, std=std),
          ])
      def __call__(self, image):
          return self.transform(image)
  ```
* ê²°ê³¼
  ![image](https://user-images.githubusercontent.com/35680202/131697331-e3fa583b-4c74-4b67-b6f4-e00cb425ba0e.png)
  * CutMixì™€ ë¹„êµí•´ì„œ ê·¸ë˜í”„ê°€ ëŒ€ì²´ë¡œ ë‚®ê³ , ì¢‹ê²Œ í•™ìŠµë˜ì§€ ëª»í•œ ì±„ early stopping ëœë‹¤.

### face crop ë‹¤ì‹œ ì ìš©í•´ë³´ê¸°

* [Facenet Pytorch](https://github.com/timesler/facenet-pytorch)
* [Retinaface Pytorch](https://github.com/biubug6/Pytorch_Retinaface)
* Dataset ì˜ `__getitem__` í•¨ìˆ˜ì— ì¶”ê°€
  ```python
  # ===== Face Crop =====
  X_PADDING = 20
  Y_PADDING = 30
  # mtcnn ì ìš©
  mtcnn = MTCNN(keep_all=True)
  boxes, probs = mtcnn.detect(image)
  if len(probs) > 1:
      xmin = int(boxes[0, 0]) - X_PADDING
      ymin = int(boxes[0, 1]) - Y_PADDING
      xmax = int(boxes[0, 2]) + X_PADDING
      ymax = int(boxes[0, 3]) + Y_PADDING
  else:
      # retinaface ì ìš©
      image_path = self.image_paths[index]
      result_detected = RetinaFace.detect_faces(image_path)
      if type(result_detected) == dict:
          xmin = int(result_detected["face_1"]["facial_area"][0]) - X_PADDING
          ymin = int(result_detected["face_1"]["facial_area"][1]) - Y_PADDING
          xmax = int(result_detected["face_1"]["facial_area"][2]) + X_PADDING
          ymax = int(result_detected["face_1"]["facial_area"][3]) + Y_PADDING
      else:
          # ì§ì ‘ crop
          xmin = 80
          ymin = 50
          xmax = 80 + 220
          ymax = 50 + 320
  if xmin < 0: xmin = 0
  if ymin < 0: ymin = 0
  if xmax > 384: xmax = 384
  if ymax > 512: ymax = 512
  image = image.crop([xmin, ymin, xmax, ymax])
  # transform
  image_transform = self.transform(image)
  ```

### íŒ€ ì½”ë“œì— í•©ì¹˜ê³  ëŒë ¤ë³´ê¸°

- [x] CutMix ì˜®ê¸°ê¸°
- [x] Test Augmentation ì¶”ê°€í•˜ê¸°
- [x] early stopping ì¡°ê±´ ë°”ê¾¸ê¸°
- [x] ì „ì²´ ë°ì´í„°ì…‹ í•™ìŠµ ì¶”ê°€í•˜ê¸°

## ğŸš€ í•™ìŠµ íšŒê³ 

* ì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ë‹ˆê¹Œ í™•ì‹¤íˆ ì„±ëŠ¥ì´ ì¢‹ì•„ì¡Œë‹¤. train/valid ë¡œ ë‚˜ëˆ ì„œ í•™ìŠµí•œ ë‹¤ìŒì—ëŠ” ê·¸ í•™ìŠµ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµì‹œì¼œì„œ ìµœì¢… ëª¨ë¸ë¡œ ì‚¬ìš©í•´ì•¼ê² ë‹¤.
* íŒ€ ì½”ë“œë¡œ í•©ì¹˜ëŠ” ì‘ì—…ì´ ì²˜ìŒì—ëŠ” ë²ˆê±°ë¡­ë‹¤ê³  ìƒê°í–ˆëŠ”ë°, ìƒê°ë³´ë‹¤ ë„ˆë¬´ ìœ ìš©í•˜ê³ , íš¨ìœ¨ì ì´ì—ˆë‹¤. ì•ìœ¼ë¡œ ì§„í–‰ë˜ëŠ” ëŒ€íšŒì—ì„œë„ ì´ëŸ¬í•œ íŒ€ í˜‘ì—…ì„ ì˜ ì§„í–‰í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì€ ìì‹ ê°ì´ ìƒê²¼ë‹¤.

